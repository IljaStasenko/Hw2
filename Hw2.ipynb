{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d706a777-198a-4171-bd3f-bd0dc9b83ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "def read_image(filename, byteorder='>'):\n",
    "    \n",
    "    #first we read the image, as a raw file to the buffer\n",
    "    with open(filename, 'rb') as f:\n",
    "        buffer = f.read()\n",
    "    \n",
    "    #using regex, we extract the header, width, height and maxval of the image\n",
    "    header, width, height, maxval = re.search(\n",
    "        b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
    "    \n",
    "    #then we convert the image to numpy array using np.frombuffer which interprets buffer as one dimensional array\n",
    "    return np.frombuffer(buffer,\n",
    "                            dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n",
    "                            count=int(width)*int(height),\n",
    "                            offset=len(header)\n",
    "                            ).reshape((int(height), int(width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c303dc-32a3-4e58-8624-dcbf2f1c0474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 92)\n"
     ]
    }
   ],
   "source": [
    "img = read_image('data/training/s1/1.pgm')\n",
    "Image.open(\"data/training/s1/1.pgm\")\n",
    "print(img.shape)\n",
    "size = 2\n",
    "total_sample_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2745e80-7aac-4ad2-b175-10c4f3e770f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size, total_sample_size):\n",
    "    #read the image\n",
    "    image = read_image('data/training/s' + str(1) + '/' + str(1) + '.pgm', 'rw+')\n",
    "    #reduce the size\n",
    "    image = image[::size, ::size]\n",
    "    #get the new size\n",
    "    dim1 = image.shape[0]\n",
    "    dim2 = image.shape[1]\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    #initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2]\n",
    "    x_geuine_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2]) # 2 is for pairs\n",
    "    y_genuine = np.zeros([total_sample_size, 1])\n",
    "    \n",
    "    for i in range(40):\n",
    "        for j in range(int(total_sample_size/40)):\n",
    "            ind1 = 0\n",
    "            ind2 = 0\n",
    "            \n",
    "            #read images from same directory (genuine pair)\n",
    "            while ind1 == ind2:\n",
    "                ind1 = np.random.randint(10)\n",
    "                ind2 = np.random.randint(10)\n",
    "            \n",
    "            # read the two images\n",
    "            img1 = read_image('data/training/s' + str(i+1) + '/' + str(ind1 + 1) + '.pgm', 'rw+')\n",
    "            img2 = read_image('data/training/s' + str(i+1) + '/' + str(ind2 + 1) + '.pgm', 'rw+')\n",
    "            \n",
    "            #reduce the size\n",
    "            img1 = img1[::size, ::size]\n",
    "            img2 = img2[::size, ::size]\n",
    "            \n",
    "            #store the images to the initialized numpy array\n",
    "            x_geuine_pair[count, 0, 0, :, :] = img1\n",
    "            x_geuine_pair[count, 1, 0, :, :] = img2\n",
    "            \n",
    "            #as we are drawing images from the same directory we assign label as 1. (genuine pair)\n",
    "            y_genuine[count] = 1\n",
    "            count += 1\n",
    "\n",
    "    count = 0\n",
    "    x_imposite_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2])\n",
    "    y_imposite = np.zeros([total_sample_size, 1])\n",
    "    \n",
    "    for i in range(int(total_sample_size/10)):\n",
    "        for j in range(10):\n",
    "            \n",
    "            #read images from different directory (imposite pair)\n",
    "            while True:\n",
    "                ind1 = np.random.randint(40)\n",
    "                ind2 = np.random.randint(40)\n",
    "                if ind1 != ind2:\n",
    "                    break\n",
    "                    \n",
    "            img1 = read_image('data/training/s' + str(ind1+1) + '/' + str(j + 1) + '.pgm', 'rw+')\n",
    "            img2 = read_image('data/training/s' + str(ind2+1) + '/' + str(j + 1) + '.pgm', 'rw+')\n",
    "\n",
    "            img1 = img1[::size, ::size]\n",
    "            img2 = img2[::size, ::size]\n",
    "\n",
    "            x_imposite_pair[count, 0, 0, :, :] = img1\n",
    "            x_imposite_pair[count, 1, 0, :, :] = img2\n",
    "            #as we are drawing images from the different directory we assign label as 0. (imposite pair)\n",
    "            y_imposite[count] = 0\n",
    "            count += 1\n",
    "            \n",
    "    #now, concatenate, genuine pairs and imposite pair to get the whole data\n",
    "    X = np.concatenate([x_geuine_pair, x_imposite_pair], axis=0)/255\n",
    "    Y = np.concatenate([y_genuine, y_imposite], axis=0)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c864e04-68f1-42b1-8590-58c1ad6df789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2, 1, 56, 46)\n",
      "(20000, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_data(size, total_sample_size)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09df6504-b0d0-4441-a5aa-58febd56ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_network(input_shape):\n",
    "    \n",
    "    seq = Sequential()    \n",
    "    nb_filter = [6, 12]\n",
    "    kernel_size = 3    \n",
    "    \n",
    "    #convolutional layer 1\n",
    "    seq.add(Convolution2D(nb_filter[0], kernel_size, kernel_size, input_shape=input_shape,\n",
    "                          padding='valid', data_format=\"channels_first\"))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "    seq.add(Dropout(.25))\n",
    "    \n",
    "    #convolutional layer 2\n",
    "    seq.add(Convolution2D(nb_filter[1], kernel_size, kernel_size, padding='valid', data_format=\"channels_first\"))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")) \n",
    "    seq.add(Dropout(.25))\n",
    "\n",
    "    #flatten \n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(128, activation='relu'))\n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(50, activation='relu'))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4277d47a-2446-487a-8c2f-9134cfcfdbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Илья\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_dim = x_train.shape[2:]\n",
    "input_a = Input(input_dim)\n",
    "input_b = Input(input_dim)\n",
    "\n",
    "base_network = build_base_network(input_dim)\n",
    "feat_vecs_a = base_network(input_a)\n",
    "feat_vecs_b = base_network(input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559228e1-5658-44c9-be66-5d4965843d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    euclidean_distance = K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "    #print(euclidean_distance)\n",
    "    return euclidean_distance\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebf0cdd-4ac2-453d-a01b-5097ef0fd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])\n",
    "\n",
    "epochs = 16\n",
    "rms = RMSprop()\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=distance)\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb9bd629-e17a-42cb-b61c-cdee96e86408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=contrastive_loss, optimizer=rms)\n",
    "img_1 = x_train[:, 0]\n",
    "img_2 = x_train[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddfb594d-ef3a-4712-af1c-aaf99412adcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Илья\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor', 'keras_tensor_1']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 - 4s - 40ms/step - loss: 0.2545 - val_loss: 0.4170\n",
      "Epoch 2/16\n",
      "88/88 - 2s - 28ms/step - loss: 0.2499 - val_loss: 0.3827\n",
      "Epoch 3/16\n",
      "88/88 - 3s - 29ms/step - loss: 0.2414 - val_loss: 0.3510\n",
      "Epoch 4/16\n",
      "88/88 - 2s - 28ms/step - loss: 0.2306 - val_loss: 0.3117\n",
      "Epoch 5/16\n",
      "88/88 - 2s - 28ms/step - loss: 0.2169 - val_loss: 0.2668\n",
      "Epoch 6/16\n",
      "88/88 - 2s - 28ms/step - loss: 0.2066 - val_loss: 0.2496\n",
      "Epoch 7/16\n",
      "88/88 - 3s - 29ms/step - loss: 0.2004 - val_loss: 0.2115\n",
      "Epoch 8/16\n",
      "88/88 - 2s - 28ms/step - loss: 0.1915 - val_loss: 0.1930\n",
      "Epoch 9/16\n",
      "88/88 - 2s - 28ms/step - loss: 0.1845 - val_loss: 0.1842\n",
      "Epoch 10/16\n",
      "88/88 - 2s - 28ms/step - loss: 0.1820 - val_loss: 0.1765\n",
      "Epoch 11/16\n",
      "88/88 - 3s - 29ms/step - loss: 0.1761 - val_loss: 0.1649\n",
      "Epoch 12/16\n",
      "88/88 - 2s - 28ms/step - loss: 0.1723 - val_loss: 0.1703\n",
      "Epoch 13/16\n",
      "88/88 - 3s - 28ms/step - loss: 0.1691 - val_loss: 0.1516\n",
      "Epoch 14/16\n",
      "88/88 - 3s - 28ms/step - loss: 0.1678 - val_loss: 0.1484\n",
      "Epoch 15/16\n",
      "88/88 - 3s - 29ms/step - loss: 0.1655 - val_loss: 0.1486\n",
      "Epoch 16/16\n",
      "88/88 - 2s - 28ms/step - loss: 0.1621 - val_loss: 0.1423\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "0.115252115\n",
      "0.7360145146658603\n"
     ]
    }
   ],
   "source": [
    "model.fit([img_1, img_2], y_train, validation_split=.25, batch_size=128, verbose=2, epochs=epochs)\n",
    "pred = model.predict([x_test[:, 0], x_test[:, 1]])\n",
    "\n",
    "print(pred.var())\n",
    "def compute_accuracy(predictions, labels):\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n",
    "print(compute_accuracy(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1957947-f2a1-4291-80c2-0f1a4ba0a71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('data/result/model.weights.h5')\n",
    "with open('data/result/model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())\n",
    "print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a7227-ba31-4e7b-9707-74bbdac4e3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
